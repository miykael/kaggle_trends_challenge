{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0      # modifiable seed\n",
    "CLF_SS = 1      # sub-sample model types for faster run\n",
    "TARGETS = 0    # which target (0-4) to predict; -1 for all\n",
    "nfolds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np  \n",
    "import pandas as pd \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (15, 5.5)\n",
    "\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "if SEED < 0:\n",
    "    np.random.seed(datetime.datetime.now().microsecond)\n",
    "else:\n",
    "    np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "\n",
    "X = np.load(os.path.join(path, 'X_tr_%02d.npy' % TARGETS))\n",
    "X_te = np.load(os.path.join(path, 'X_te_%02d.npy' % TARGETS))\n",
    "y = np.load(os.path.join(path, 'y_tr_%02d.npy' % TARGETS))\n",
    "groups = np.random.randint(0, nfolds, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)\n",
    "X_te = pd.DataFrame(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(np.reshape(list(y) *5, (5, -1)).T, columns=['age', 'd11', 'd12', 'd21', 'd22'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, RepeatedKFold, KFold, ShuffleSplit\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr_params = {\n",
    "    'kernel': [  'rbf',  ] , \n",
    "    'C': [1],\n",
    "    'gamma': [ 'scale'],\n",
    "    'nu': [0.5] }\n",
    "\n",
    "def trainNuSVR(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = NuSVR(cache_size=100, tol = 1e-3)\n",
    "    params = nusvr_params        \n",
    "    return trainModel(x, y, groups, clf, params, cv, n_jobs,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_params = { 'alpha': np.logspace(-8, 1, 2),\n",
    "                'l1_ratio': [ 0.5]}\n",
    "\n",
    "def trainENet(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = ElasticNet(normalize = False, selection = 'random', max_iter = 1000, tol = 1e-3 )\n",
    "    return trainModel(x, y, groups, clf, enet_params, cv, n_jobs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnae(y_true, y_pred, tidx=0):\n",
    "    mean_ = np.array([ 50.00929913, 374.75058741, 462.62996118, 332.46733185, 381.32490681])\n",
    "    scale_ = np.array([ 13.54897461, 108.25005321, 128.03349126, 112.01700719, 124.92278531])\n",
    "\n",
    "    t_true = y_true * scale_[tidx] + mean_[tidx]\n",
    "    t_pred = y_pred * scale_[tidx] + mean_[tidx]\n",
    "\n",
    "    if tidx == 0:\n",
    "        age_values = np.unique(t_true)\n",
    "        for i, a in enumerate(t_pred):\n",
    "            t_pred[i] = age_values[np.argmin(np.abs(a-age_values))]\n",
    "\n",
    "    if tidx > 0:\n",
    "        t_true = np.power(t_true, 1./1.5)\n",
    "        t_pred = np.power(t_pred, 1./1.5)\n",
    "    score = np.mean(np.sum(np.abs(t_true - t_pred), axis=0) / np.sum(t_true, axis=0))\n",
    "    return score\n",
    "\n",
    "fnae_scorer = make_scorer(fnae, greater_is_better = False, tidx=TARGETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x, y, groups, clf, params, cv = 0, n_jobs = None, \n",
    "                   verbose=0, splits=None, **kwargs):\n",
    "    if n_jobs is None:\n",
    "        n_jobs = -1    \n",
    "\n",
    "    n_iter = 3\n",
    "    n_splits = 2\n",
    "        \n",
    "    folds = ShuffleSplit(n_splits = n_splits, train_size = 0.75, test_size = 0.20)\n",
    "    clf = RandomizedSearchCV(clf, params, cv = folds, n_iter = n_iter, \n",
    "                            verbose = 1, n_jobs = n_jobs, scoring = fnae_scorer)\n",
    "    \n",
    "    f = clf.fit(x, y, groups)\n",
    "    \n",
    "    print(pd.DataFrame(clf.cv_results_['mean_test_score'])); print();  \n",
    "    best = clf.best_estimator_;  print(best)\n",
    "    print(\"Best Score: {}\".format(np.round(clf.best_score_,4)))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBag(n = 3, model_type = trainENet, data = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "\n",
    "    \"\"\"\n",
    "    valid = ~y.isnull()\n",
    "    X = X[valid]; y = y[valid]; groups = groups[valid]\n",
    "    \"\"\"\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    clfs = []; preds = []; ys=[]; datestack = []\n",
    "    for group in group_list:\n",
    "        g = gc.collect()\n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[groups != group]\n",
    "        y_train = y[groups != group]\n",
    "        \n",
    "        groups_train = groups[groups != group]\n",
    "\n",
    "        model = model_type \n",
    "        clf = model(x_train, y_train, groups_train, **kwargs) \n",
    "        clfs.append(clf)\n",
    "\n",
    "        predicted = clf.predict(x_holdout)\n",
    "        print(\"{}: {:.4f}\".format(group,\n",
    "              fnae(y_holdout, predicted)  ) )\n",
    "        \n",
    "        preds.append(predicted)\n",
    "        ys.append(y_holdout)\n",
    "    \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_ho = np.concatenate(ys) \n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\nModel Bag Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBaseClfs(clfs, clf_names, data, target = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "        \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    X_ordered = []; y_ordered = []; groups_ordered =[]  \n",
    "    all_base_clfs = []; base_preds = [[] for i in range(0, 5 * len(clfs))]; \n",
    "    for group in group_list:\n",
    "        print(\"Training Fold {} of {}:\".format(group, len(group_list)))\n",
    "        np.random.seed(SEED)\n",
    "        \n",
    "        x_holdout = X[groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[groups != group]\n",
    "        y_train = y[groups != group]\n",
    "\n",
    "        y_idx = ALL_TARGETS.index(target)\n",
    "        \n",
    "        X_ordered.append(x_holdout)\n",
    "        y_ordered.append(y_holdout)\n",
    "        groups_ordered.append(groups[groups == group])\n",
    "        \n",
    "        base_clfs = []\n",
    "        for idx, clf in enumerate(clfs):\n",
    "            base_clfs.append(clone(clf))\n",
    "        \n",
    "        def train_model(model, X, y):\n",
    "            ss = (~pd.DataFrame(y).isnull().any(axis=1))\n",
    "            model.fit(X[ss], y[ss]); return model\n",
    "        \n",
    "        base_clfs = Parallel(n_jobs=-1)(delayed(train_model)(model, x_train, y_train[y_var]) for model in base_clfs)\n",
    "        all_base_clfs.append(base_clfs)\n",
    "        \n",
    "        def predict_model(model, X):\n",
    "            o = model.predict(X); return o    \n",
    "        preds = Parallel(n_jobs=-1)(delayed(predict_model)(model, x_holdout) for model in base_clfs)\n",
    "        \n",
    "        \n",
    "        pidx = 0; clf_pred_names = []\n",
    "        for idx, clf in enumerate(base_clfs):   \n",
    "            print(\"{:.4f} for {}\".format( \n",
    "                      fnae(y_holdout[target], preds[idx]), clf_names[idx]  ) )\n",
    "            base_preds[pidx].append(preds[idx]); pidx+=1;\n",
    "            clf_pred_names.append(clf_names[idx])\n",
    "            \n",
    "        print(\"\\nTime Elapsed: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "        \n",
    "    base_preds = base_preds[:len(clf_pred_names)]\n",
    "    for idx in range(0, len(base_preds)):\n",
    "        base_preds[idx] = np.concatenate(base_preds[idx])\n",
    "\n",
    "    \n",
    "    print(\"\\Base Classifier Train Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "    return (all_base_clfs, base_preds, clf_pred_names, \n",
    "        pd.concat(X_ordered), pd.concat(y_ordered), np.concatenate(groups_ordered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lassos():\n",
    "    clfs = []; clf_names = []\n",
    "    lassos =  np.logspace(-6, -1, 2)\n",
    "    for l in lassos:\n",
    "        clfs.append(Lasso(alpha = l,  selection = 'random', max_iter = 500, tol = 1e-3))\n",
    "        clf_names.append('Lasso alpha={}'.format(l))\n",
    "        if CLF_SS > 1:\n",
    "            clfs.append(clfs[-1]); clf_names.append(clf_names[-1])\n",
    " \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ridges():\n",
    "    clfs = []; clf_names = []\n",
    "    ridges =  np.logspace(-4, 2, 2)\n",
    "    for r in ridges:\n",
    "        clfs.append(Ridge(alpha = r, max_iter = 500, tol = 1e-3))\n",
    "        clf_names.append('Ridge alpha={}'.format(r))\n",
    "        if CLF_SS > 1:\n",
    "            clfs.append(clfs[-1]); clf_names.append(clf_names[-1])\n",
    "\n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVRs():\n",
    "    clfs = []; clf_names = []\n",
    "    svrs =  (np.logspace(-1.5, 0.5, 2), [0.01, 0.1]) \n",
    "    for c in svrs[0]:\n",
    "        for e in svrs[1]:\n",
    "            clfs.append(SVR(C = c, epsilon = e, cache_size=1000, max_iter = 500, tol = 1e-3))\n",
    "            clf_names.append('SVR C={}, epsilon={}'.format(c,e))\n",
    "            \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ENets():\n",
    "    clfs = []; clf_names = []\n",
    "    enets = (np.logspace(-6, -1, 41), [0.98]) \n",
    "    for a in enets[0]:\n",
    "        for l in enets[1]:\n",
    "            clfs.append(ElasticNet(alpha = a, l1_ratio = l,\n",
    "                         normalize = False, selection = 'random', \n",
    "                         max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('Enet alpha={}, l1_ratio={}'.format(a,l))\n",
    " \n",
    "    for a in enets[0]:\n",
    "        for l in enets[1]:\n",
    "            clfs.append(ElasticNet(alpha = a, l1_ratio = l,\n",
    "                         normalize = True, selection = 'random', \n",
    "                         max_iter = 5000, tol = 1e-5))\n",
    "            clf_names.append('Enet-n alpha={}, l1_ratio={}'.format(a,l))\n",
    "            \n",
    "    return clfs, clf_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaseClfs(y_var, model_sets=None):\n",
    "    idx = ALL_TARGETS.index(y_var)\n",
    "\n",
    "    clfs = []\n",
    "    clf_names = []\n",
    "    \n",
    "    for model_set in model_sets:\n",
    "        clfs.extend(model_set[0])\n",
    "        clf_names.extend(model_set[1])\n",
    "   \n",
    "\n",
    "    return clfs[::CLF_SS], clf_names[::CLF_SS];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TARGETS = y.columns.to_list()  \n",
    "if isinstance(TARGETS, list):\n",
    "    targets = [ALL_TARGETS[i] for i in TARGETS]\n",
    "elif TARGETS is not None and TARGETS >= 0:\n",
    "    targets = ALL_TARGETS[TARGETS: TARGETS + 1]\n",
    "else:\n",
    "    targets = ALL_TARGETS\n",
    "# print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_raw_base_clfs = []; all_base_clfs = []; scalers = []\n",
    "y_var = targets[0]\n",
    "\n",
    "print('---Training Models for {}---\\n'.format(y_var))\n",
    "\n",
    "# train base classifiers\n",
    "model_sets=[Ridges(), Lassos()]\n",
    "raw_base_clfs, base_clf_names = getBaseClfs(y_var, model_sets=model_sets)\n",
    "all_raw_base_clfs.append((raw_base_clfs, base_clf_names))\n",
    "\n",
    "base_clfs, base_clf_preds, base_clf_names, Xe, ye, ge = \\\n",
    "                trainBaseClfs(raw_base_clfs, base_clf_names, \n",
    "                              data = (X, y, groups), \n",
    "                              target=y_var, )\n",
    "Xe = pd.concat( (Xe, pd.DataFrame( dict(zip(base_clf_names, base_clf_preds)), index=Xe.index) ),\n",
    "                 axis = 'columns')\n",
    "\n",
    "all_base_clfs.append((base_clfs, base_clf_preds, base_clf_names, Xe, ye, ge ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metaFilter(X):\n",
    "    return X[[c for c in X.columns if c not in X_te.columns ]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBag(n = 3, model_types = None, data = None, **kwargs):\n",
    "    start_time = datetime.datetime.now(); \n",
    "    \n",
    "    X, y, groups = data\n",
    "    \n",
    "    group_list = [*dict.fromkeys(groups)]   \n",
    "    group_list.sort()\n",
    "    \n",
    "    clfs = []; preds = []; ys=[]; datestack = []\n",
    "    for midx, group in enumerate(group_list):\n",
    "        g = gc.collect()\n",
    "        x_holdout = X[midx][groups == group]\n",
    "        y_holdout = y[groups == group]\n",
    "        x_train = X[midx][groups != group]\n",
    "        y_train = y[groups != group]\n",
    "        \n",
    "        groups_train = groups[groups != group]\n",
    "\n",
    "        model = model_types[midx]\n",
    "        clf = model(x_train, y_train, groups_train, **kwargs) \n",
    "        clfs.append(clf)\n",
    "\n",
    "        predicted = clf.predict(x_holdout)\n",
    "        print(\"{}: {:.4f}\".format(group,\n",
    "              fnae(y_holdout, predicted)  ) )\n",
    "        \n",
    "        preds.append(predicted)\n",
    "        ys.append(y_holdout)\n",
    "    \n",
    "    y_pred = np.concatenate(preds)\n",
    "    y_ho = np.concatenate(ys) \n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\nModel Bag Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(x, y, groups, clf, params, cv = 0, n_jobs = None, \n",
    "                   verbose=0, splits=None, **kwargs):\n",
    "    if n_jobs is None:\n",
    "        n_jobs = -1    \n",
    "\n",
    "    n_iter = 30\n",
    "    n_splits = 10\n",
    "        \n",
    "    n_iter = 3\n",
    "    n_splits = 2\n",
    "        \n",
    "    folds = ShuffleSplit(n_splits = n_splits, train_size = 0.75, test_size = 0.20)\n",
    "    clf = RandomizedSearchCV(clf, params, cv = folds, n_iter = n_iter, \n",
    "                            verbose = 1, n_jobs = n_jobs, scoring = fnae_scorer)\n",
    "    \n",
    "    f = clf.fit(x, y, groups)\n",
    "    \n",
    "    print(pd.DataFrame(clf.cv_results_['mean_test_score'])); print();  \n",
    "    best = clf.best_estimator_;  print(best)\n",
    "    print(\"Best Score: {}\".format(np.round(clf.best_score_,4)))\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP\n",
    "\n",
    "change values back for train classifiers\n",
    "slightly increase SVR?\n",
    "also reset n_iter and n_splits above\n",
    "n_iter perhaps to 100 to have more reliable results? or even 150?\n",
    "also increase resolution of ranges... of these trainModels, it's anyhow randomsearch\n",
    "\n",
    "also, slightly increase SVR C from previous part?\n",
    "\n",
    "also verify that all n_jobs are set to -1 (there are a few 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr_params = {\n",
    "    'kernel': [  'rbf',  ] , \n",
    "    'C': [1],\n",
    "    'gamma': [ 'scale'],\n",
    "    'nu': [0.5] }\n",
    "\n",
    "def trainNuSVR(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = NuSVR(cache_size=100, tol = 1e-3)\n",
    "    params = nusvr_params        \n",
    "    return trainModel(x, y, groups, clf, params, cv, n_jobs,  **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_params = { 'alpha': np.logspace(-8, 1, 2),\n",
    "                'l1_ratio': [ 0.5]}\n",
    "\n",
    "def trainENet(x, y, groups, cv = 0, n_jobs = -1, **kwargs):\n",
    "    clf = ElasticNet(normalize = False, selection = 'random', max_iter = 1000, tol = 1e-3 )\n",
    "    return trainModel(x, y, groups, clf, enet_params, cv, n_jobs, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run metaclassifers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_scalers = [StandardScaler()] * 5\n",
    "meta_models = [trainENet] * 5\n",
    "\n",
    "scalers_stand = [s.fit(metaFilter(Xe)) for s in meta_scalers]\n",
    "all_clfs_stand = [runBag(data = ([s.transform(metaFilter(Xe)) for s in scalers_stand], ye[y_var], ge), model_types = meta_models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_scalers = [FunctionTransformer()] * 5\n",
    "meta_models = [trainNuSVR] * 5\n",
    "\n",
    "scalers_func = [s.fit(metaFilter(Xe)) for s in meta_scalers]\n",
    "all_clfs_func = [runBag(data = ([s.transform(metaFilter(Xe)) for s in scalers_stand], ye[y_var], ge), model_types = meta_models)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revert_transform(y_true, y_pred, tidx=0):\n",
    "    mean_ = np.array([ 50.00929913, 374.75058741, 462.62996118, 332.46733185, 381.32490681])\n",
    "    scale_ = np.array([ 13.54897461, 108.25005321, 128.03349126, 112.01700719, 124.92278531])\n",
    "\n",
    "    t_true = y_true * scale_[tidx] + mean_[tidx]\n",
    "    t_pred = y_pred * scale_[tidx] + mean_[tidx]\n",
    "\n",
    "    age_values = np.unique(t_true)\n",
    "    for i, a in enumerate(t_pred):\n",
    "        t_pred[i] = age_values[np.argmin(np.abs(a-age_values))]\n",
    "\n",
    "    if tidx > 0:\n",
    "        t_true = np.power(t_true, 1./1.5)\n",
    "        t_pred = np.power(t_pred, 1./1.5)\n",
    "    return np.squeeze(t_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAll(X_test, all_base_clfs, all_clfs, all_scalers):\n",
    "    start_time = datetime.datetime.now(); \n",
    "        \n",
    "    def predict_model(model, X):\n",
    "        o = model.predict(X)\n",
    "        return o    \n",
    "    \n",
    "    all_preds = pd.DataFrame(columns = targets, index=X_test.index)\n",
    "    for tidx, y_var in enumerate(targets): # loop over targets\n",
    "        print(y_var)\n",
    "        Xi = X_test.copy()\n",
    "        base_clfs = all_base_clfs[tidx][0]\n",
    "\n",
    "        preds = []; \n",
    "        for g_idx, g_clfs in enumerate(base_clfs): # loop over groups\n",
    "            print(g_idx)\n",
    "            preds.append(Parallel(n_jobs=-1)(delayed(predict_model)(g_clfs[mhm], Xi) for mhm in range(len(g_clfs))))\n",
    "        print(\"\\Base Classifier Prediction Time: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    "\n",
    "        c_preds = []; sub_preds = np.zeros((len(preds), len(Xi)))\n",
    "        for c_idx in range(0, len(preds[0])):  \n",
    "            if len(preds[0][c_idx].shape) > 1: \n",
    "                for t_idx in range(0, preds[0][c_idx].shape[1]):\n",
    "                    for g_idx, this_pred_group in enumerate(preds):  \n",
    "                        sub_preds[g_idx, :] = this_pred_group[c_idx][:, t_idx]\n",
    "                    c_preds.append(np.mean( sub_preds, axis = 0))  \n",
    "            else:\n",
    "                for g_idx, this_pred_group in enumerate(preds): \n",
    "                    sub_preds[g_idx, :] = this_pred_group[c_idx]\n",
    "                c_preds.append(np.mean( sub_preds, axis = 0)) \n",
    "\n",
    "        Xf = pd.concat( (Xi, pd.DataFrame( dict(zip(all_base_clfs[tidx][2], c_preds)), index=Xi.index) ),\n",
    "                     axis = 'columns')\n",
    "        print(\"\\nTime Elapsed: {}\\n\".format(str(datetime.datetime.now() - start_time).split('.', 2)[0] ))\n",
    " \n",
    "        print('\\nrunning stacker')\n",
    "        mmodels = all_clfs[tidx]\n",
    "        pred = Parallel(n_jobs=-1)(delayed(predict_model)(mmodels[aidx], all_scalers[aidx].transform(metaFilter(Xf)))\n",
    "                                  for aidx in range(5))\n",
    "        sub_preds = np.zeros((len(all_clfs[tidx]), len(Xi)))\n",
    "        for g_idx, clf in enumerate(all_clfs[tidx]):\n",
    "            sub_preds[g_idx, :] = pred[g_idx]\n",
    "        all_preds[y_var] = np.mean(sub_preds, axis = 0)\n",
    "\n",
    "    end_time = datetime.datetime.now(); \n",
    "    print(\"\\Prediction Time: {}\\n\".format(str(end_time - start_time).split('.', 2)[0] ))\n",
    "    return all_preds, Xf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos_stand, Xf = predictAll(X_te, all_base_clfs, all_clfs_stand, scalers_stand)\n",
    "s_pred_stand = revert_transform(y.iloc[:, TARGETS].values, y_oos_stand.values, tidx=TARGETS)\n",
    "pd.DataFrame(s_pred_stand).to_csv('submission_%02d_stand.csv' % TARGETS, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos_func, Xf = predictAll(X_te, all_base_clfs, all_clfs_func, scalers_func)\n",
    "s_pred_func = revert_transform(y.iloc[:, TARGETS].values, y_oos_func.values, tidx=TARGETS)\n",
    "pd.DataFrame(s_pred_func).to_csv('submission_%02d_func.csv' % TARGETS, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which priorities should be chosen?\n",
    "meta_selecter = [0, 1, 1, 0, 0]\n",
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers_comb = list(np.array([scalers_stand, scalers_func])[meta_selecter, 0])\n",
    "all_clfs_comb = [list(np.array([all_clfs_stand[0], all_clfs_func[0]])[meta_selecter, 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oos_comb, Xf = predictAll(X_te, all_base_clfs, all_clfs_comb, scalers_comb)\n",
    "s_pred_comb = revert_transform(y.iloc[:, TARGETS].values, y_oos_comb.values, tidx=TARGETS)\n",
    "pd.DataFrame(s_pred_comb).to_csv('submission_%02d_comb.csv' % TARGETS, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neuro] *",
   "language": "python",
   "name": "conda-env-neuro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
